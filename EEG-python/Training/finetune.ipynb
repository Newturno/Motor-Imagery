{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pongk\\.virtualenvs\\EEG-python-MGW7v3UV\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import create_dataloader\n",
    "from dataset import EEG\n",
    "import wandb\n",
    "from mne.datasets import sample\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "# Now do your import\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvNet,CNN2D,ConvNet_physionet,ConvNet2\n",
    "from torchsummary import summary\n",
    "net = ConvNet2().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute\n",
    "#net.load_state_dict(torch.load('./save_weight/sunsun/sunsun_85.1852'))\n",
    "online_path = \"/Users/Pongk/Desktop/Work/mi-project/EEG-python/Training/save_weight/S18_newConv_irr_-2-5_8-13_3ch/0.6852_S18_newConv_irr_-2-5_8-13_3ch_0.6852_55.1282.pth\"\n",
    "\n",
    "# MI\n",
    "net.load_state_dict(torch.load(online_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['layer1.0.weight', 'layer1.0.bias', 'layer1.1.weight', 'layer1.1.bias', 'layer1.1.running_mean', 'layer1.1.running_var', 'layer1.1.num_batches_tracked', 'layer2.0.weight', 'layer2.0.bias', 'layer2.1.weight', 'layer2.1.bias', 'layer2.1.running_mean', 'layer2.1.running_var', 'layer2.1.num_batches_tracked', 'layer3.0.weight', 'layer3.0.bias', 'layer3.1.weight', 'layer3.1.bias', 'layer3.1.running_mean', 'layer3.1.running_var', 'layer3.1.num_batches_tracked', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms = net.state_dict()\n",
    "parms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad and 'layer1' in name:\n",
    "        param.requires_grad = False\n",
    "    if param.requires_grad and 'layer2' in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Pongk/Desktop/Work/mi-project/EEG-python/dataset/recorded_EEG\n",
      "Raw done\n",
      "Filter done\n"
     ]
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = \"./dataset/finetune_EEG/\"\n",
    "path = RECORED_PATH\n",
    "#subject to run\n",
    "#runs = [3,5,7,9]\n",
    "runs = [14,15,16,17,18]\n",
    "subjects = [18]\n",
    "#recorded eeg class\n",
    "eeg = EEG(path, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "\n",
    "print(\"Raw done\")\n",
    "# apply filter \n",
    "X,y = eeg.raw_preprocess(raw)\n",
    "X = eeg.apply_baseline(X)\n",
    "# iir_param = dict(order=5, ftype='butter', output='sos')\n",
    "# raw=raw.notch_filter([50])\n",
    "# #raw=raw.filter(8,14,method = 'iir',iir_params=iir_param,phase='zero')\n",
    "# raw = raw.filter(8,14, method='fir', verbose=20)\n",
    "print(\"Filter done\")\n",
    "# # apply filter \n",
    "# iir_param = dict(order=5, ftype='butter', output='sos')\n",
    "# raw=raw.notch_filter([50])\n",
    "# #raw=raw.filter(8,14,method = 'iir',iir_params=iir_param,phase='zero')\n",
    "# raw = raw.filter(8,14, method='fir', verbose=20)\n",
    "# print(\"Filter done\")\n",
    "\n",
    "# epochs=eeg.epochs(raw,tmin=-3,tmax=5,baseline=(-3,0))\n",
    "# #X = X[:, :,np.newaxis,:]\n",
    "# X, y = eeg.get_X_y(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (70, 3, 1750) (70,)\n",
      "Test size (30, 3, 1750) (30,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\n",
    "\n",
    "print('train size',X_train.shape, y_train.shape)\n",
    "print('Test size',X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1750\n",
    "\n",
    "train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "num_step =math.ceil(len(train_loader.dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpongkorn-set\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Pongk\\Desktop\\Work\\mi-project\\EEG-python\\Training\\wandb\\run-20230926_142738-2fizr53h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pongkorn-set/Motor-imagery/runs/2fizr53h' target=\"_blank\">CNN_S18_Finetune_conv2_online_2ch</a></strong> to <a href='https://wandb.ai/pongkorn-set/Motor-imagery' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pongkorn-set/Motor-imagery' target=\"_blank\">https://wandb.ai/pongkorn-set/Motor-imagery</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pongkorn-set/Motor-imagery/runs/2fizr53h' target=\"_blank\">https://wandb.ai/pongkorn-set/Motor-imagery/runs/2fizr53h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "wand = wandb.init(\n",
    "        \n",
    "      # Set the project where this run will be logged\n",
    "      project=\"Motor-Imagery\", \n",
    "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"CNN_S18_Finetune_conv2_online_2ch\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.0000001,\n",
    "      \"architecture\": \"CNN\",\n",
    "      \"dataset\": \"Finetune\",\n",
    "      \"epochs\": 300000,\n",
    "      \"weightname\":\"S18_Finetune_conv2_online_3ch\",\n",
    "      \"num_step_per_epoch\" : num_step, \n",
    "        \n",
    "      }\n",
    "    )\n",
    "\n",
    "config = wand.config\n",
    "print(config.num_step_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300000, Tr Loss: 0.8523, Tr Acc: 42.8571, Val Loss: 0.6989, Val Acc: 46.6667\n",
      "Epoch 101/300000, Tr Loss: 0.8048, Tr Acc: 47.1429, Val Loss: 0.7053, Val Acc: 46.6667\n",
      "Epoch 201/300000, Tr Loss: 0.8122, Tr Acc: 47.1429, Val Loss: 0.7051, Val Acc: 46.6667\n",
      "Epoch 301/300000, Tr Loss: 0.8259, Tr Acc: 41.4286, Val Loss: 0.7052, Val Acc: 46.6667\n",
      "Epoch 401/300000, Tr Loss: 0.7668, Tr Acc: 51.4286, Val Loss: 0.7051, Val Acc: 46.6667\n",
      "Epoch 501/300000, Tr Loss: 0.7841, Tr Acc: 47.1429, Val Loss: 0.7048, Val Acc: 46.6667\n",
      "Epoch 601/300000, Tr Loss: 0.7561, Tr Acc: 47.1429, Val Loss: 0.7050, Val Acc: 46.6667\n",
      "Epoch 701/300000, Tr Loss: 0.7673, Tr Acc: 50.0000, Val Loss: 0.7049, Val Acc: 46.6667\n",
      "Epoch 801/300000, Tr Loss: 0.7899, Tr Acc: 54.2857, Val Loss: 0.7050, Val Acc: 46.6667\n",
      "Epoch 901/300000, Tr Loss: 0.7727, Tr Acc: 48.5714, Val Loss: 0.7051, Val Acc: 46.6667\n",
      "Epoch 1001/300000, Tr Loss: 0.7578, Tr Acc: 50.0000, Val Loss: 0.7051, Val Acc: 46.6667\n",
      "Epoch 1101/300000, Tr Loss: 0.7417, Tr Acc: 45.7143, Val Loss: 0.7051, Val Acc: 46.6667\n",
      "Epoch 1201/300000, Tr Loss: 0.7433, Tr Acc: 51.4286, Val Loss: 0.7049, Val Acc: 50.0000\n",
      "Epoch 1301/300000, Tr Loss: 0.8576, Tr Acc: 42.8571, Val Loss: 0.7049, Val Acc: 50.0000\n",
      "Epoch 1401/300000, Tr Loss: 0.7491, Tr Acc: 48.5714, Val Loss: 0.7050, Val Acc: 50.0000\n",
      "Epoch 1501/300000, Tr Loss: 0.7163, Tr Acc: 55.7143, Val Loss: 0.7050, Val Acc: 50.0000\n",
      "Epoch 1601/300000, Tr Loss: 0.8741, Tr Acc: 31.4286, Val Loss: 0.7050, Val Acc: 50.0000\n",
      "Epoch 1701/300000, Tr Loss: 0.8158, Tr Acc: 41.4286, Val Loss: 0.7050, Val Acc: 50.0000\n",
      "Epoch 1801/300000, Tr Loss: 0.7677, Tr Acc: 44.2857, Val Loss: 0.7051, Val Acc: 50.0000\n"
     ]
    }
   ],
   "source": [
    "from utils import train\n",
    "config = wand.config\n",
    "optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "\n",
    "train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "    model = net,\n",
    "    loader_train = train_loader,\n",
    "    loader_test = test_loader,\n",
    "    vail_loader = None,\n",
    "    optimizer = optimizer  ,\n",
    "    criterion = criterion ,\n",
    "    device = 'cuda',\n",
    "    wand = wand\n",
    ")\n",
    "\n",
    "wandb.alert(\n",
    "            title='Finish',\n",
    "            text=f'Finishing training',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71ee62090f476f7f208daa0d546a5a64db59508b1a22febc715667ce49424855"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
