{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import pywt\n",
    "from mne.time_frequency import tfr_multitaper\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.cuda as cuda\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "from utils import create_dataloader,train,bandpower\n",
    "from dataset import EEG\n",
    "import wandb\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "# Now do your import\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pongkornsettasompop/Desktop/work/Motor-Imagery/EEG-python/dataset/recorded_EEG\n",
      "Raw done\n"
     ]
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#C:\\Users\\Pongk\\Desktop\\Work\\mi-project\\EEG-python\\dataset\\recorded_EEG\n",
    "path = RECORED_PATH\n",
    "#path = \"/root/EEG_Model/dataset/finetune_EEG/\"\n",
    "#subject to run\n",
    "runs = [2,3,4,6,8,12,15,17,18,22]\n",
    "#runs = [1,2,3,4,12,13,14,15,16,17]\n",
    "#runs = [1]\n",
    "#runs = [7,8,9,10]\n",
    "subjects = [17]\n",
    "#recorded eeg class\n",
    "eeg = EEG(path, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "\n",
    "print(\"Raw done\")\n",
    "# apply filter \n",
    "#iir_param = dict(order=5, ftype='butter', output='sos')\n",
    "#raw=raw.notch_filter([50])\n",
    "#raw=raw.filter(8,14,method = 'iir',iir_params=iir_param,phase='zero')\n",
    "#raw.filter(8,13, method='fir', verbose=\"error\")\n",
    "#print(\"Filter done\")\n",
    "#raw=eeg.raw_ica()\n",
    "#eeg.create_epochs()\n",
    "raw = raw._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 4 but corresponding boolean dimension is 234144",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/pongkornsettasompop/Desktop/work/Motor-Imagery/EEG-python/Training/training.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pongkornsettasompop/Desktop/work/Motor-Imagery/EEG-python/Training/training.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(raw))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pongkornsettasompop/Desktop/work/Motor-Imagery/EEG-python/Training/training.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m sf\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pongkornsettasompop/Desktop/work/Motor-Imagery/EEG-python/Training/training.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m bp \u001b[39m=\u001b[39m bandpower(raw, sf, [\u001b[39m0.5\u001b[39;49m, \u001b[39m4\u001b[39;49m], \u001b[39m'\u001b[39;49m\u001b[39mmultitaper\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pongkornsettasompop/Desktop/work/Motor-Imagery/EEG-python/Training/training.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m bp_rel \u001b[39m=\u001b[39m bandpower(raw, sf, [\u001b[39m0.5\u001b[39m, \u001b[39m4\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mmultitaper\u001b[39m\u001b[39m'\u001b[39m, relative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pongkornsettasompop/Desktop/work/Motor-Imagery/EEG-python/Training/training.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAbsolute delta power: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m bp)\n",
      "File \u001b[0;32m~/Desktop/work/Motor-Imagery/EEG-python/Training/utils.py:225\u001b[0m, in \u001b[0;36mbandpower\u001b[0;34m(data, sf, band, method, window_sec, relative)\u001b[0m\n\u001b[1;32m    222\u001b[0m idx_band \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_and(freqs \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m low, freqs \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m high)\n\u001b[1;32m    224\u001b[0m \u001b[39m# Integral approximation of the spectrum using parabola (Simpson's rule)\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m bp \u001b[39m=\u001b[39m simps(psd[idx_band], dx\u001b[39m=\u001b[39mfreq_res)\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m relative:\n\u001b[1;32m    228\u001b[0m     bp \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m simps(psd, dx\u001b[39m=\u001b[39mfreq_res)\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 4 but corresponding boolean dimension is 234144"
     ]
    }
   ],
   "source": [
    "#Feature extraction\n",
    "# Multitaper delta powe\n",
    "print(type(raw))\n",
    "sf=250\n",
    "bp = bandpower(raw, sf, [0.5, 4], 'multitaper')\n",
    "bp_rel = bandpower(raw, sf, [0.5, 4], 'multitaper', relative=True)\n",
    "print('Absolute delta power: %.3f' % bp)\n",
    "print('Relative delta power: %.3f' % bp_rel)\n",
    "\n",
    "# Delta-beta ratio\n",
    "# One advantage of the multitaper is that we don't need to define a window length.\n",
    "db = bandpower(raw, sf, [0.5, 4], 'multitaper') / bandpower(raw, sf, [12, 30], 'multitaper')\n",
    "# Ratio based on the relative power\n",
    "db_rel = bandpower(raw, sf, [0.5, 4], 'multitaper', relative=True) / \\\n",
    "                    bandpower(raw, sf, [12, 30], 'multitaper', relative=True)\n",
    "print('Delta/beta ratio (absolute): %.3f' % db)\n",
    "print('Delta/beta ratio (relative): %.3f' % db_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = eeg.raw_preprocess(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X[0,0,:])\n",
    "print(y)\n",
    "\n",
    "X = eeg.apply_baseline(X)\n",
    "X = np.transpose(X,(0,2,1))\n",
    "print(X[0,0,:])\n",
    "print(np.transpose(X,(0,2,1)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs=eeg.epochs(raw,tmin=-2,tmax=5,baseline=(-2,0))\n",
    "print(len(epochs.times))\n",
    "#X = X[:, :,np.newaxis,:]\n",
    "X, y = eeg.get_X_y(epochs)\n",
    "#(250*5)\n",
    "#normal version \n",
    "#X = X[:,:,(250*3):]\n",
    "\n",
    "#new version\n",
    "#X = X[:,:,(250*8):(250*13)]\n",
    "\n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "#new_X = np.concatenate((fixation_X,imagine_X),axis=2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old version use X. New version use new_X\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\n",
    "print('Train size',X_train.shape, y_train.shape)\n",
    "print('Test size',X_test.shape, y_test.shape)\n",
    "print(y_train)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1750\n",
    "\n",
    "train_loader = create_dataloader(X_train, y_train, batch_size=batch_size)\n",
    "test_loader = create_dataloader(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "num_step =math.ceil(len(train_loader.dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wand setup\n",
    "#\"weightname\":\"S12_3-9_fir8-14\"\n",
    "#name=f\"CNN_S12_3-9_fir8-14\",\n",
    "wandb.login()\n",
    "wand = wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"Motor-Imagery-New\", \n",
    "      # We pass a run name (otherwise itâ€™ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=f\"TransR2_S17_iir_-2-5_8-13_3ch\", \n",
    "      # Track hyperparameters and run metadata\n",
    "      # 0.0000001\n",
    "      config={\n",
    "      \"learning_rate\": 0.0000001,\n",
    "      \"architecture\": \"ConvNet\",\n",
    "      \"dataset\": \"Recorded\",\n",
    "      \"epochs\": 100000,\n",
    "      \"weightname\":\"S17_TransformeR2_iir_-2-5_8-13_3ch\",\n",
    "      \"num_step_per_epoch\" : num_step, \n",
    "      }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvNet,CNN2D,gamenet,ConvNet2\n",
    "from torchsummary import summary\n",
    "from transformer import Transformer\n",
    "# net = ConvNet2()\n",
    "\n",
    "device = 'cuda'\n",
    "sequence_len=1750 # sequence length of time series\n",
    "max_len=5000 # max time series sequence length \n",
    "n_head = 4 # number of attention head\n",
    "n_layer = 2 # number of encoder layer\n",
    "drop_prob = 0.1\n",
    "d_model = 200 # number of dimension ( for positional embedding)\n",
    "ffn_hidden = 512 # size of hidden layer before classification \n",
    "in_features = 3 # for univariate time series (1d), it must be adjusted for 1. \n",
    "n_classes = 2\n",
    "net =  Transformer( in_features=in_features,\n",
    "                     d_model=d_model,\n",
    "                     details=False,\n",
    "                     n_head=n_head,\n",
    "                     max_len=max_len,\n",
    "                     seq_len=sequence_len,\n",
    "                     ffn_hidden=ffn_hidden,\n",
    "                     n_layers=n_layer,\n",
    "                     drop_prob=drop_prob,\n",
    "                     n_classes=n_classes,\n",
    "                     device=device\n",
    "                     )\n",
    "#summary(net, (2, 641),32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train\n",
    "config = wand.config\n",
    "optimizer = optim.Adam(net.parameters(), lr=config.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "\n",
    "train_loss,valid_loss,train_accuracy,valid_accuracy =train(\n",
    "    model = net,\n",
    "    loader_train = train_loader,\n",
    "    loader_test = test_loader,\n",
    "    vail_loader = None,\n",
    "    optimizer = optimizer  ,\n",
    "    criterion = criterion ,\n",
    "    device = 'cuda',\n",
    "    wand = wand\n",
    ")\n",
    "\n",
    "\n",
    "wandb.alert(\n",
    "            title='Finish',\n",
    "            text=f'Finishing training',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchsummary import summary\n",
    "from transformer import Transformer\n",
    " \n",
    "\n",
    "sequence_len=1750 # sequence length of time series\n",
    "max_len=5000 # max time series sequence length \n",
    "n_head = 4 # number of attention head\n",
    "n_layer = 2 # number of encoder layer\n",
    "drop_prob = 0.1\n",
    "d_model = 200 # number of dimension ( for positional embedding)\n",
    "ffn_hidden = 512 # size of hidden layer before classification \n",
    "in_features = 3 # for univariate time series (1d), it must be adjusted for 1. \n",
    "n_classes = 2\n",
    "model =  Transformer( in_features=in_features,\n",
    "                     d_model=d_model,\n",
    "                     details=False,\n",
    "                     n_head=n_head,\n",
    "                     max_len=max_len,\n",
    "                     seq_len=sequence_len,\n",
    "                     ffn_hidden=ffn_hidden,\n",
    "                     n_layers=n_layer,\n",
    "                     drop_prob=drop_prob,\n",
    "                     n_classes=n_classes,\n",
    "                     device=device)\n",
    "\n",
    "batch_size = 555\n",
    "\n",
    "#summary(net, (2, 641),32)\n",
    "#summary(model, input_size=(batch_size,sequence_len,feature))\n",
    "\n",
    "input_ = torch.from_numpy(np.empty((batch_size,sequence_len,in_features))).float()\n",
    "\n",
    "model(input_)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71ee62090f476f7f208daa0d546a5a64db59508b1a22febc715667ce49424855"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
